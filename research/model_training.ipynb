{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dung/Code/Project\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "file_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))  # Change this if your file is in a different folder\n",
    "os.chdir(file_dir)\n",
    "\n",
    "print(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "# Import from the models package\n",
    "from models import MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'lstm'  # Choose from: 'random_forest', 'sarimax', 'lstm', 'gru', 'arima', 'xgboost'\n",
    "HIDDEN_DIM = 128\n",
    "EPOCHS = 50\n",
    "# DATA_PATH = 'BTC_with_indicators.csv'  # Path to your data\n",
    "TEST_SIZE = 0.2\n",
    "TIME_STEPS = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.hidden_dim = HIDDEN_DIM\n",
    "        self.epochs = EPOCHS\n",
    "        self.time_steps = TIME_STEPS     # Use 7 days of historical data\n",
    "        self.target_horizon = 24  # Predict next 24 hours\n",
    "        self.test_size = 0.2\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_and_preprocess_data(data_path):\n",
    "#     \"\"\"Load, validate and preprocess the data.\"\"\"\n",
    "#     print(f\"Loading data from {data_path}\")\n",
    "#     data = pd.read_csv(data_path)\n",
    "    \n",
    "#     # Display data info\n",
    "#     print(\"Data shape:\", data.shape)\n",
    "#     print(\"Data columns:\", data.columns.tolist())\n",
    "#     print(\"First few rows:\")\n",
    "#     print(data.head())\n",
    "    \n",
    "#     # Validate data columns\n",
    "#     expected_columns = ['Date', 'close', 'volume', 'sma_20', 'macd', 'rsi', 'bb_bbm']\n",
    "#     for col in expected_columns:\n",
    "#         if col not in data.columns:\n",
    "#             print(f\"Warning: Expected column '{col}' not found in data!\")\n",
    "    \n",
    "#     # Preprocess data\n",
    "#     data['Date'] = pd.to_datetime(data['Date'])\n",
    "#     data = data.sort_values('Date')\n",
    "    \n",
    "#     # Make sure data has consistent structure for training and testing\n",
    "#     # This ensures both train and test data have the same columns in the same order\n",
    "#     selected_columns = ['Date', 'close', 'volume', 'sma_20', 'macd', 'rsi', 'bb_bbm']\n",
    "#     available_columns = [col for col in selected_columns if col in data.columns]\n",
    "    \n",
    "#     if len(available_columns) < len(selected_columns):\n",
    "#         print(f\"Warning: Using only available columns: {available_columns}\")\n",
    "    \n",
    "#     data = data[available_columns]\n",
    "    \n",
    "#     if 'close' in data.columns and data.columns[-1] != 'close':\n",
    "#         cols = [col for col in data.columns if col != 'close']\n",
    "#         cols.append('close')\n",
    "#         data = data[cols]\n",
    "#         print(\"Rearranged columns to put 'close' at the end:\", data.columns.tolist())\n",
    "\n",
    "#     # Handle any missing values to prevent issues\n",
    "#     for col in data.columns:\n",
    "#         if data[col].isnull().any():\n",
    "#             print(f\"Filling missing values in column '{col}'\")\n",
    "#             if col == 'Date':\n",
    "#                 # Can't have missing dates, so drop those rows\n",
    "#                 data = data.dropna(subset=['Date'])\n",
    "#             else:\n",
    "#                 # For numeric columns, fill with median or forward fill\n",
    "#                 data[col] = data[col].fillna(method='ffill')\n",
    "#                 # If there are still NaNs (e.g., at the beginning), fill with median\n",
    "#                 data[col] = data[col].fillna(data[col].median() if data[col].median() is not np.nan else 0)\n",
    "    \n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from utils.mongodb import load_collection_to_dataframe\n",
    "\n",
    "def load_and_preprocess_data(collection_name):\n",
    "    data = load_collection_to_dataframe(collection_name)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(model_name, args, train_data, test_data, save_path=None):\n",
    "    \"\"\"\n",
    "    Train model and make predictions with the specified model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_name : str\n",
    "        Name of the model to use (key in MODELS dictionary)\n",
    "    args : object\n",
    "        Arguments for model initialization\n",
    "    train_data : DataFrame\n",
    "        Training data\n",
    "    test_data : DataFrame\n",
    "        Testing data\n",
    "    save_path : str, optional\n",
    "        Path to save the trained model\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    model : Model instance\n",
    "        Trained model\n",
    "    predictions : ndarray or DataFrame\n",
    "        Model predictions\n",
    "    \"\"\"\n",
    "    # Ensure test data has the exact same structure as training data\n",
    "    train_columns = train_data.columns.tolist()\n",
    "    test_columns = test_data.columns.tolist()\n",
    "    \n",
    "    if train_columns != test_columns:\n",
    "        print(f\"Warning: Train and test data columns don't match.\")\n",
    "        print(f\"Train columns: {train_columns}\")\n",
    "        print(f\"Test columns: {test_columns}\")\n",
    "        \n",
    "        # Make sure test data has the same columns as training data\n",
    "        common_columns = [col for col in train_columns if col in test_columns]\n",
    "        train_data = train_data[common_columns]\n",
    "        test_data = test_data[common_columns]\n",
    "        print(f\"Using common columns: {common_columns}\")\n",
    "    \n",
    "    # Initialize and train model\n",
    "    ModelClass = MODELS[model_name]\n",
    "    model = ModelClass(args)\n",
    "    \n",
    "    print(f\"Training the {model_name} model...\")\n",
    "    model.fit(train_data)\n",
    "    \n",
    "    # Save the model if path is provided\n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        model_save_path = os.path.join(save_path, f\"{model_name}_model\")\n",
    "        print(f\"Saving model to {model_save_path}\")\n",
    "        model.save(model_save_path)\n",
    "    \n",
    "    # Make predictions\n",
    "    print(\"Making predictions...\")\n",
    "    predictions = model.predict(test_data)\n",
    "    \n",
    "    return model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_results(results, model_name, feature_names=None, output_dir='results'):\n",
    "    \"\"\"\n",
    "    Create and save visualizations of prediction results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : DataFrame\n",
    "        DataFrame with actual and predicted values\n",
    "    model_name : str\n",
    "        Name of the model used\n",
    "    feature_names : list, optional\n",
    "        Names of the features predicted\n",
    "    output_dir : str\n",
    "        Directory to save plots\n",
    "    \"\"\"\n",
    "    # Create plots directory if it doesn't exist\n",
    "    plots_dir = os.path.join(output_dir, 'plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Get dates\n",
    "    dates = results['Date']\n",
    "    \n",
    "    # Determine if we have multiple features or a single feature\n",
    "    if feature_names is not None and len(feature_names) > 1:\n",
    "        # Multiple features case (like OHLCV)\n",
    "        \n",
    "        # Create a separate plot for each feature\n",
    "        for feature in feature_names:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(dates, results[f'Actual_{feature}'], label=f'Actual {feature}', marker='o', linestyle='-', markersize=3)\n",
    "            plt.plot(dates, results[f'Predicted_{feature}'], label=f'Predicted {feature}', marker='x', linestyle='--', markersize=3)\n",
    "            \n",
    "            plt.title(f'{model_name}: Actual vs Predicted {feature}')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Value')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the plot\n",
    "            plot_file = os.path.join(plots_dir, f'{model_name}_{feature}_comparison.png')\n",
    "            plt.savefig(plot_file)\n",
    "            plt.close()\n",
    "            print(f\"Plot saved to {plot_file}\")\n",
    "        \n",
    "        # Create a combined plot for all features\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i, feature in enumerate(feature_names):\n",
    "            plt.subplot(len(feature_names), 1, i+1)\n",
    "            plt.plot(dates, results[f'Actual_{feature}'], label=f'Actual', color='blue', alpha=0.7)\n",
    "            plt.plot(dates, results[f'Predicted_{feature}'], label=f'Predicted', color='red', alpha=0.7)\n",
    "            plt.title(feature)\n",
    "            plt.ylabel('Value')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Only show x-axis for the bottom subplot\n",
    "            if i < len(feature_names) - 1:\n",
    "                plt.xticks([])\n",
    "            else:\n",
    "                plt.xlabel('Date')\n",
    "                plt.xticks(rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        combined_plot_file = os.path.join(plots_dir, f'{model_name}_all_features.png')\n",
    "        plt.savefig(combined_plot_file)\n",
    "        plt.close()\n",
    "        print(f\"Combined plot saved to {combined_plot_file}\")\n",
    "    else:\n",
    "        # Single feature case\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(dates, results['Actual'], label='Actual', marker='o', linestyle='-', markersize=3)\n",
    "        plt.plot(dates, results['Predicted'], label='Predicted', marker='x', linestyle='--', markersize=3)\n",
    "        \n",
    "        plt.title(f'{model_name}: Actual vs Predicted')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        plot_file = os.path.join(plots_dir, f'{model_name}_comparison.png')\n",
    "        plt.savefig(plot_file)\n",
    "        plt.close()\n",
    "        print(f\"Plot saved to {plot_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "def evaluate_and_save_results(actual_values, predictions, model_name, test_dates=None, output_dir='results'):\n",
    "    \"\"\"\n",
    "    Evaluate model performance and save results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    actual_values : ndarray or DataFrame\n",
    "        Actual target values\n",
    "    predictions : ndarray or DataFrame\n",
    "        Model predictions\n",
    "    model_name : str\n",
    "        Name of the model used\n",
    "    test_dates : ndarray or Series, optional\n",
    "        Dates corresponding to test data\n",
    "    output_dir : str, optional\n",
    "        Directory to save results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    metrics : dict\n",
    "        Dictionary of evaluation metrics\n",
    "    results : DataFrame\n",
    "        DataFrame with actual and predicted values\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Store column names if available\n",
    "    if isinstance(actual_values, pd.DataFrame):\n",
    "        actual_column_names = actual_values.columns.tolist()\n",
    "        actual_values_np = actual_values.values\n",
    "    else:\n",
    "        actual_column_names = None\n",
    "        actual_values_np = actual_values\n",
    "        \n",
    "    if isinstance(predictions, pd.DataFrame):\n",
    "        pred_column_names = predictions.columns.tolist()\n",
    "        predictions_np = predictions.values\n",
    "    else:\n",
    "        pred_column_names = None\n",
    "        predictions_np = predictions\n",
    "    \n",
    "    # Reshape if needed for single-feature cases\n",
    "    if len(actual_values_np.shape) == 1:\n",
    "        actual_values_np = actual_values_np.reshape(-1, 1)\n",
    "    if len(predictions_np.shape) == 1:\n",
    "        predictions_np = predictions_np.reshape(-1, 1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {}\n",
    "    \n",
    "    # For multi-output case (like OHLCV prediction)\n",
    "    if actual_values_np.shape[1] > 1:\n",
    "        print(f\"Evaluating {actual_values_np.shape[1]} output features:\")\n",
    "        metrics['mse'] = []\n",
    "        metrics['rmse'] = []\n",
    "        metrics['mae'] = []\n",
    "        metrics['r2'] = []\n",
    "        \n",
    "        # Calculate metrics for each output feature\n",
    "        for i in range(actual_values_np.shape[1]):\n",
    "            # Fixed feature name handling\n",
    "            if actual_column_names is not None:\n",
    "                feature_name = actual_column_names[i]\n",
    "            else:\n",
    "                feature_name = f\"Feature {i}\"\n",
    "                \n",
    "            mse = mean_squared_error(actual_values_np[:, i], predictions_np[:, i])\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(actual_values_np[:, i], predictions_np[:, i])\n",
    "            r2 = r2_score(actual_values_np[:, i], predictions_np[:, i])\n",
    "            \n",
    "            metrics['mse'].append(mse)\n",
    "            metrics['rmse'].append(rmse)\n",
    "            metrics['mae'].append(mae)\n",
    "            metrics['r2'].append(r2)\n",
    "            \n",
    "            print(f\"{feature_name}:\")\n",
    "            print(f\"  MSE: {mse:.4f}\")\n",
    "            print(f\"  RMSE: {rmse:.4f}\")\n",
    "            print(f\"  MAE: {mae:.4f}\")\n",
    "            print(f\"  R²: {r2:.4f}\")\n",
    "            \n",
    "        # Calculate average metrics\n",
    "        metrics['avg_mse'] = np.mean(metrics['mse'])\n",
    "        metrics['avg_rmse'] = np.mean(metrics['rmse'])\n",
    "        metrics['avg_mae'] = np.mean(metrics['mae'])\n",
    "        metrics['avg_r2'] = np.mean(metrics['r2'])\n",
    "        \n",
    "        print(\"\\nAverage metrics:\")\n",
    "        print(f\"  Avg MSE: {metrics['avg_mse']:.4f}\")\n",
    "        print(f\"  Avg RMSE: {metrics['avg_rmse']:.4f}\")\n",
    "        print(f\"  Avg MAE: {metrics['avg_mae']:.4f}\")\n",
    "        print(f\"  Avg R²: {metrics['avg_r2']:.4f}\")\n",
    "    else:\n",
    "        # For single output case\n",
    "        mse = mean_squared_error(actual_values_np, predictions_np)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(actual_values_np, predictions_np)\n",
    "        r2 = r2_score(actual_values_np, predictions_np)\n",
    "        \n",
    "        metrics['mse'] = mse\n",
    "        metrics['rmse'] = rmse\n",
    "        metrics['mae'] = mae\n",
    "        metrics['r2'] = r2\n",
    "        \n",
    "        print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "        print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "        print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "        print(f\"R² Score: {r2:.4f}\")\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    if test_dates is None:\n",
    "        # Create dummy dates if not provided\n",
    "        test_dates = pd.date_range(start='today', periods=len(actual_values_np)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Create results DataFrame based on whether we have multiple outputs\n",
    "    if actual_values_np.shape[1] > 1:\n",
    "        # For multiple outputs (like OHLCV)\n",
    "        results = pd.DataFrame({'Date': test_dates})\n",
    "        \n",
    "        # Add actual and predicted values for each feature\n",
    "        for i in range(actual_values_np.shape[1]):\n",
    "            if actual_column_names is not None:\n",
    "                feature_name = actual_column_names[i]\n",
    "            else:\n",
    "                feature_name = f\"Feature_{i}\"\n",
    "                \n",
    "            results[f\"Actual_{feature_name}\"] = actual_values_np[:, i]\n",
    "            results[f\"Predicted_{feature_name}\"] = predictions_np[:, i]\n",
    "    else:\n",
    "        # For single output\n",
    "        results = pd.DataFrame({\n",
    "            'Date': test_dates,\n",
    "            'Actual': actual_values_np.flatten(),\n",
    "            'Predicted': predictions_np.flatten()\n",
    "        })\n",
    "    \n",
    "    # Display results preview\n",
    "    print(\"\\nResults preview:\")\n",
    "    print(results.head())\n",
    "    \n",
    "    # Save results\n",
    "    results_file = os.path.join(output_dir, f'{model_name}_prediction_results.csv')\n",
    "    results.to_csv(results_file, index=False)\n",
    "    print(f\"Results saved to {results_file}\")\n",
    "    \n",
    "    # Save metrics\n",
    "    metrics_file = os.path.join(output_dir, f'{model_name}_metrics.csv')\n",
    "    \n",
    "    # Convert metrics to DataFrame and save\n",
    "    if actual_values_np.shape[1] > 1:\n",
    "        # Determine feature names for metrics dataframe\n",
    "        if actual_column_names is not None:\n",
    "            feature_names = actual_column_names\n",
    "        else:\n",
    "            feature_names = [f\"Feature_{i}\" for i in range(actual_values_np.shape[1])]\n",
    "            \n",
    "        metrics_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'MSE': metrics['mse'],\n",
    "            'RMSE': metrics['rmse'],\n",
    "            'MAE': metrics['mae'],\n",
    "            'R2': metrics['r2']\n",
    "        })\n",
    "        # Add a row for averages\n",
    "        metrics_df.loc[len(metrics_df)] = ['Average', metrics['avg_mse'], metrics['avg_rmse'], metrics['avg_mae'], metrics['avg_r2']]\n",
    "    else:\n",
    "        metrics_df = pd.DataFrame({\n",
    "            'Metric': ['MSE', 'RMSE', 'MAE', 'R2'],\n",
    "            'Value': [metrics['mse'], metrics['rmse'], metrics['mae'], metrics['r2']]\n",
    "        })\n",
    "    \n",
    "    metrics_df.to_csv(metrics_file, index=False)\n",
    "    print(f\"Metrics saved to {metrics_file}\")\n",
    "    \n",
    "    # Create output directory for plots\n",
    "    plots_dir = os.path.join(output_dir, 'plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot results\n",
    "    # Determine feature names for plotting\n",
    "    if actual_values_np.shape[1] > 1:\n",
    "        if actual_column_names is not None:\n",
    "            feature_names = actual_column_names\n",
    "        else:\n",
    "            feature_names = [f\"Feature_{i}\" for i in range(actual_values_np.shape[1])]\n",
    "            \n",
    "        # Create a separate plot for each feature\n",
    "        for i, feature in enumerate(feature_names):\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(results['Date'], results[f'Actual_{feature}'], label=f'Actual {feature}', marker='o', linestyle='-', markersize=3)\n",
    "            plt.plot(results['Date'], results[f'Predicted_{feature}'], label=f'Predicted {feature}', marker='x', linestyle='--', markersize=3)\n",
    "            \n",
    "            plt.title(f'{model_name}: Actual vs Predicted {feature}')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Value')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the plot\n",
    "            plot_file = os.path.join(plots_dir, f'{model_name}_{feature}_comparison.png')\n",
    "            plt.savefig(plot_file)\n",
    "            plt.close()\n",
    "            print(f\"Plot saved to {plot_file}\")\n",
    "        \n",
    "        # Create a combined plot for all features\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i, feature in enumerate(feature_names):\n",
    "            plt.subplot(len(feature_names), 1, i+1)\n",
    "            plt.plot(results['Date'], results[f'Actual_{feature}'], label=f'Actual', color='blue', alpha=0.7)\n",
    "            plt.plot(results['Date'], results[f'Predicted_{feature}'], label=f'Predicted', color='red', alpha=0.7)\n",
    "            plt.title(feature)\n",
    "            plt.ylabel('Value')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Only show x-axis for the bottom subplot\n",
    "            if i < len(feature_names) - 1:\n",
    "                plt.xticks([])\n",
    "            else:\n",
    "                plt.xlabel('Date')\n",
    "                plt.xticks(rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        combined_plot_file = os.path.join(plots_dir, f'{model_name}_all_features.png')\n",
    "        plt.savefig(combined_plot_file)\n",
    "        plt.close()\n",
    "        print(f\"Combined plot saved to {combined_plot_file}\")\n",
    "    else:\n",
    "        # Single feature case\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(results['Date'], results['Actual'], label='Actual', marker='o', linestyle='-', markersize=3)\n",
    "        plt.plot(results['Date'], results['Predicted'], label='Predicted', marker='x', linestyle='--', markersize=3)\n",
    "        \n",
    "        plt.title(f'{model_name}: Actual vs Predicted')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        plot_file = os.path.join(plots_dir, f'{model_name}_comparison.png')\n",
    "        plt.savefig(plot_file)\n",
    "        plt.close()\n",
    "        print(f\"Plot saved to {plot_file}\")\n",
    "    \n",
    "    return metrics, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ohlcv_training_data(data, time_steps, target_horizon=24):\n",
    "    \"\"\"\n",
    "    Prepare OHLCV data for training time series models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        Input data with datetime index and OHLCV + feature columns\n",
    "    time_steps : int\n",
    "        Number of historical time steps to use\n",
    "    target_horizon : int\n",
    "        Number of hours ahead to predict\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    train_data : DataFrame\n",
    "        Data prepared for training\n",
    "    \"\"\"\n",
    "    # Make sure datetime is the index\n",
    "    if 'datetime' in data.columns:\n",
    "        data = data.set_index('datetime')\n",
    "    \n",
    "    # Create shifted targets for future prediction\n",
    "    target_columns = ['open_price', 'high_price', 'low_price', 'close_price', 'volume_to']\n",
    "    \n",
    "    # For each target column, create a future target column\n",
    "    for col in target_columns:\n",
    "        data[f'future_{col}'] = data[col].shift(-target_horizon)\n",
    "    \n",
    "    # Drop rows with NaN values in future targets\n",
    "    data = data.dropna()\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /home/dung/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\n",
      "WARNING:py.warnings:/home/dung/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 datetime      acc_dist    volume_to        rsi      stoch  \\\n",
      "0     2020-01-02 01:00:00 -3.805598e+06   3525833.70  43.967544  20.483924   \n",
      "1     2020-01-02 02:00:00 -4.903857e+06   7263407.16  40.480699  24.000352   \n",
      "2     2020-01-02 03:00:00 -1.429354e+07  10320976.65  31.215136   1.870700   \n",
      "3     2020-01-02 04:00:00 -1.273945e+07   5756869.86  38.566021  21.278532   \n",
      "4     2020-01-02 05:00:00 -1.415696e+07   3073480.43  35.805367   9.795547   \n",
      "...                   ...           ...          ...        ...        ...   \n",
      "46382 2025-04-23 03:00:00  1.195981e+11  68746230.62  73.102815  80.601488   \n",
      "46383 2025-04-23 04:00:00  1.196489e+11  52829567.91  75.484061  92.985339   \n",
      "46384 2025-04-23 05:00:00  1.196490e+11  59313196.82  72.955363  86.768676   \n",
      "46385 2025-04-23 06:00:00  1.196473e+11  41927067.45  73.746479  91.462510   \n",
      "46386 2025-04-23 07:00:00  1.196746e+11  28921534.44  74.765764  97.388753   \n",
      "\n",
      "                obv   aroon_up  aroon_down  volume_from         macd  \\\n",
      "0     -1.093437e+07  50.000000   85.714286       487.16     4.270893   \n",
      "1     -1.819778e+07  42.857143  100.000000      1012.45     0.793421   \n",
      "2     -2.851876e+07  35.714286  100.000000      1444.77    -5.963042   \n",
      "3     -2.276189e+07  28.571429  100.000000       803.86    -9.235791   \n",
      "4     -2.583537e+07  21.428571   92.857143       428.78   -13.002922   \n",
      "...             ...        ...         ...          ...          ...   \n",
      "46382  2.635622e+10  57.142857    0.000000       739.88  1328.088090   \n",
      "46383  2.640905e+10  50.000000    0.000000       566.26  1349.194858   \n",
      "46384  2.634973e+10  42.857143    0.000000       634.46  1335.726657   \n",
      "46385  2.639166e+10  35.714286    0.000000       447.47  1322.172179   \n",
      "46386  2.642058e+10  28.571429    0.000000       308.86  1312.153119   \n",
      "\n",
      "       close_price        time  open_price  low_price  high_price        adx  \n",
      "0          7195.19  1577926800     7218.61    7186.18     7224.84   0.000000  \n",
      "1          7180.68  1577930400     7195.19    7153.37     7217.72   0.000000  \n",
      "2          7130.25  1577934000     7180.68    7127.64     7185.49  32.584263  \n",
      "3          7154.73  1577937600     7130.25    7124.34     7172.20  33.099357  \n",
      "4          7138.33  1577941200     7154.73    7128.92     7163.85  33.577658  \n",
      "...            ...         ...         ...        ...         ...        ...  \n",
      "46382     93190.14  1745377200    92898.58   92724.58    93235.24  59.531718  \n",
      "46383     93694.59  1745380800    93190.14   93059.03    93706.93  60.760950  \n",
      "46384     93511.20  1745384400    93694.59   93327.39    93694.59  61.902381  \n",
      "46385     93664.38  1745388000    93511.20   93454.86    93891.42  63.042176  \n",
      "46386     93860.79  1745391600    93664.38   93515.01    93871.23  64.100558  \n",
      "\n",
      "[46387 rows x 16 columns]\n",
      "Training data size: 37090\n",
      "Testing data size: 9273\n",
      "Training the lstm model...\n",
      "Epoch 1/50\n",
      "\u001b[1m742/742\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 8.6035e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m199/742\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0136"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m actual_values = test_data[[\u001b[33m'\u001b[39m\u001b[33mopen_price\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhigh_price\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlow_price\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mclose_price\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mvolume_to\u001b[39m\u001b[33m'\u001b[39m]].iloc[Args().time_steps:]\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Train model and make predictions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m model, predictions = \u001b[43mtrain_and_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlstm\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mArgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msaved_models\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# # Evaluate and save results\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# metrics, results = evaluate_and_save_results(\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#     actual_values, \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m \u001b[38;5;66;03m#     test_dates=test_data.index[Args().time_steps:],\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m#     output_dir='results'\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mtrain_and_predict\u001b[39m\u001b[34m(model_name, args, train_data, test_data, save_path)\u001b[39m\n\u001b[32m     42\u001b[39m model = ModelClass(args)\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Save the model if path is provided\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m save_path:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/models/LSTM.py:140\u001b[39m, in \u001b[36mMyLSTM.fit\u001b[39m\u001b[34m(self, df)\u001b[39m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m.create_model(X.shape[\u001b[32m2\u001b[39m])  \u001b[38;5;66;03m# Number of features\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m history = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\n\u001b[32m    146\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = load_and_preprocess_data('BTC_technical_indicators')\n",
    "print(data)\n",
    "# Prepare data for OHLCV prediction\n",
    "prepared_data = prepare_ohlcv_training_data(data, time_steps=Args().time_steps, target_horizon=Args().target_horizon)\n",
    "\n",
    "# Split data\n",
    "train_size = int(len(prepared_data) * (1 - Args().test_size))\n",
    "train_data = prepared_data.iloc[:train_size]\n",
    "test_data = prepared_data.iloc[train_size:]\n",
    "print(f\"Training data size: {len(train_data)}\")\n",
    "print(f\"Testing data size: {len(test_data)}\")\n",
    "\n",
    "# Extract actual values for evaluation\n",
    "actual_values = test_data[['open_price', 'high_price', 'low_price', 'close_price', 'volume_to']].iloc[Args().time_steps:]\n",
    "\n",
    "# Train model and make predictions\n",
    "model, predictions = train_and_predict('lstm', Args(), train_data, test_data, save_path='saved_models')\n",
    "\n",
    "# # Evaluate and save results\n",
    "# metrics, results = evaluate_and_save_results(\n",
    "#     actual_values, \n",
    "#     predictions, \n",
    "#     'lstm', \n",
    "#     test_dates=test_data.index[Args().time_steps:],\n",
    "#     output_dir='results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 5 output features:\n",
      "open_price:\n",
      "  MSE: 31310846.7383\n",
      "  RMSE: 5595.6096\n",
      "  MAE: 3594.3146\n",
      "  R²: 0.8686\n",
      "high_price:\n",
      "  MSE: 14087248.3114\n",
      "  RMSE: 3753.2983\n",
      "  MAE: 2362.0835\n",
      "  R²: 0.9414\n",
      "low_price:\n",
      "  MSE: 5598412.5827\n",
      "  RMSE: 2366.0965\n",
      "  MAE: 1701.4179\n",
      "  R²: 0.9763\n",
      "close_price:\n",
      "  MSE: 8618764.8465\n",
      "  RMSE: 2935.7733\n",
      "  MAE: 1983.2958\n",
      "  R²: 0.9638\n",
      "volume_to:\n",
      "  MSE: 18161811500534476.0000\n",
      "  RMSE: 134765765.3135\n",
      "  MAE: 69263115.4490\n",
      "  R²: 0.0616\n",
      "\n",
      "Average metrics:\n",
      "  Avg MSE: 3632362312029949.5000\n",
      "  Avg RMSE: 26956083.2182\n",
      "  Avg MAE: 13854551.3122\n",
      "  Avg R²: 0.7623\n",
      "\n",
      "Results preview:\n",
      "                 Date  Actual_open_price  Predicted_open_price  \\\n",
      "0 2024-03-31 00:00:00           69629.99          68563.523438   \n",
      "1 2024-03-31 01:00:00           69892.21          69107.312500   \n",
      "2 2024-03-31 02:00:00           70054.61          69154.984375   \n",
      "3 2024-03-31 03:00:00           69988.29          69059.273438   \n",
      "4 2024-03-31 04:00:00           69936.72          69049.539062   \n",
      "\n",
      "   Actual_high_price  Predicted_high_price  Actual_low_price  \\\n",
      "0           69972.31          69231.820312          69601.39   \n",
      "1           70097.17          69805.765625          69858.85   \n",
      "2           70156.39          69871.648438          69937.40   \n",
      "3           70003.78          69781.406250          69792.94   \n",
      "4           70132.75          69743.460938          69891.19   \n",
      "\n",
      "   Predicted_low_price  Actual_close_price  Predicted_close_price  \\\n",
      "0         68761.687500            69892.21           69102.421875   \n",
      "1         69383.156250            70054.61           69732.546875   \n",
      "2         69450.382812            69988.29           69779.664062   \n",
      "3         69345.171875            69936.72           69661.156250   \n",
      "4         69323.851562            70120.06           69640.695312   \n",
      "\n",
      "   Actual_volume_to  Predicted_volume_to  \n",
      "0       27819538.08           77679520.0  \n",
      "1       29496321.08           71582840.0  \n",
      "2       36166701.77           77569416.0  \n",
      "3       18925392.39           79401744.0  \n",
      "4       21089339.72           72608752.0  \n",
      "Results saved to results/lstm_prediction_results.csv\n",
      "Metrics saved to results/lstm_metrics.csv\n",
      "Plot saved to results/plots/lstm_open_price_comparison.png\n",
      "Plot saved to results/plots/lstm_high_price_comparison.png\n",
      "Plot saved to results/plots/lstm_low_price_comparison.png\n",
      "Plot saved to results/plots/lstm_close_price_comparison.png\n",
      "Plot saved to results/plots/lstm_volume_to_comparison.png\n",
      "Combined plot saved to results/plots/lstm_all_features.png\n"
     ]
    }
   ],
   "source": [
    "metrics, results = evaluate_and_save_results(\n",
    "    actual_values, \n",
    "    predictions, \n",
    "    'lstm', \n",
    "    test_dates=test_data.index[Args().time_steps:],\n",
    "    output_dir='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
