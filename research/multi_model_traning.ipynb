{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dung/Code/Project/intro-ds-project\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "file_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))  # Change this if your file is in a different folder\n",
    "os.chdir(file_dir)\n",
    "\n",
    "print(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dung/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-23 14:16:11.594879: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745392571.647987    7013 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745392571.667831    7013 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745392571.789371    7013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745392571.789434    7013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745392571.789438    7013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745392571.789441    7013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-23 14:16:11.802956: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Importing plotly failed. Interactive plots will not work.\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "# Import from the models package\n",
    "from models import MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load Hydra-style configs\n",
    "def load_config(model_type='lstm'):\n",
    "    # Load the model-specific config\n",
    "    model_config_path = f\"configs/hydra/model/{model_type}.yaml\"\n",
    "    with open(model_config_path, 'r') as f:\n",
    "        model_config = yaml.safe_load(f)\n",
    "    \n",
    "    # Load the common config\n",
    "    common_config_path = \"configs/model/common.yaml\"\n",
    "    if os.path.exists(common_config_path):\n",
    "        with open(common_config_path, 'r') as f:\n",
    "            common_config = yaml.safe_load(f)\n",
    "        # Merge common and model configs\n",
    "        for key, value in common_config.items():\n",
    "            if key not in model_config:\n",
    "                model_config[key] = value\n",
    "    \n",
    "    # Load the data config\n",
    "    data_config_path = \"configs/data/default.yaml\"\n",
    "    with open(data_config_path, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    # Create the full config\n",
    "    config = {\n",
    "        'model': model_config,\n",
    "        'data': data_config\n",
    "    }\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    \"\"\"Class to store model parameters\"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        for key, value in cfg['model'].items():\n",
    "            setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(data_path):\n",
    "    \"\"\"Load, validate and preprocess the data.\"\"\"\n",
    "    print(f\"Loading data from {data_path}\")\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    # Display data info\n",
    "    print(\"Data shape:\", data.shape)\n",
    "    print(\"Data columns:\", data.columns.tolist())\n",
    "    print(\"First few rows:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    # Validate data columns\n",
    "    expected_columns = ['Date', 'close', 'volume', 'sma_20', 'macd', 'rsi', 'bb_bbm']\n",
    "    for col in expected_columns:\n",
    "        if col not in data.columns:\n",
    "            print(f\"Warning: Expected column '{col}' not found in data!\")\n",
    "    \n",
    "    # Preprocess data\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data = data.sort_values('Date')\n",
    "    \n",
    "    # Ensure 'close' (target variable) is the last column for time series prediction\n",
    "    if 'close' in data.columns and data.columns[-1] != 'close':\n",
    "        # Rearrange columns to put 'close' at the end\n",
    "        cols = [col for col in data.columns if col != 'close']\n",
    "        cols.append('close')\n",
    "        data = data[cols]\n",
    "        print(\"Rearranged columns to place 'close' as the last column for prediction\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(model_name, args, train_data, test_data):\n",
    "    \"\"\"Train model and make predictions.\"\"\"\n",
    "    # Initialize and train model\n",
    "    ModelClass = MODELS[model_name]\n",
    "    model = ModelClass(args)\n",
    "    \n",
    "    print(f\"Training the {model_name.upper()} model...\")\n",
    "    model.fit(train_data)\n",
    "    \n",
    "    # Make predictions\n",
    "    print(\"Making predictions...\")\n",
    "    predictions = model.predict(test_data)\n",
    "    \n",
    "    return predictions, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_results(test_data, predictions, model_name):\n",
    "    \"\"\"Evaluate model and save results.\"\"\"\n",
    "    # Evaluate model - the target variable should be the last column ('close')\n",
    "    actual_values = test_data.iloc[:, -1].values.reshape(-1, 1)  # Get the last column values\n",
    "    \n",
    "    # Make sure predictions and actual values have the same shape\n",
    "    if len(predictions) != len(actual_values):\n",
    "        print(f\"Warning: Predictions length ({len(predictions)}) doesn't match actual values length ({len(actual_values)})\")\n",
    "        # Trim to the shorter length if needed\n",
    "        min_len = min(len(predictions), len(actual_values))\n",
    "        predictions = predictions[:min_len]\n",
    "        actual_values = actual_values[:min_len]\n",
    "    \n",
    "    mse = np.mean((predictions - actual_values) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    mae = np.mean(np.abs(predictions - actual_values))\n",
    "    mape = np.mean(np.abs((actual_values - predictions) / np.maximum(np.ones_like(actual_values) * 1e-8, np.abs(actual_values)))) * 100\n",
    "    \n",
    "    print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "    print(f\"Mean Absolute Percentage Error: {mape:.4f}%\")\n",
    "    \n",
    "    # Create and save results\n",
    "    results = pd.DataFrame({\n",
    "        'Date': test_data['Date'].values[:len(predictions)],\n",
    "        'Actual': actual_values.flatten(),\n",
    "        'Predicted': predictions.flatten(),\n",
    "        'Error': (actual_values - predictions).flatten()\n",
    "    })\n",
    "    \n",
    "    print(\"Results preview:\")\n",
    "    print(results.head())\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = f\"outputs/{datetime.now().strftime('%Y-%m-%d')}/{model_name}_{datetime.now().strftime('%H-%M-%S')}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    results_file = os.path.join(output_dir, f'{model_name}_prediction_results.csv')\n",
    "    results.to_csv(results_file, index=False)\n",
    "    print(f\"Results saved to {results_file}\")\n",
    "    \n",
    "    return {\n",
    "        'mse': mse, \n",
    "        'rmse': rmse, \n",
    "        'mae': mae, \n",
    "        'mape': mape, \n",
    "        'results': results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 14:16:15.789394: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/dung/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "  path: stock_data.csv\n",
      "  test_size: 0.2\n",
      "model:\n",
      "  defaults:\n",
      "  - _self_\n",
      "  - common\n",
      "  epochs: 50\n",
      "  hidden_dim: 256\n",
      "  is_regression: true\n",
      "  type: lstm\n",
      "\n",
      "Model parameters:\n",
      "defaults: ['_self_', 'common']\n",
      "type: lstm\n",
      "hidden_dim: 256\n",
      "epochs: 50\n",
      "is_regression: True\n",
      "Loading data from stock_data.csv\n",
      "Data shape: (1436, 7)\n",
      "Data columns: ['Date', 'close', 'volume', 'sma_20', 'macd', 'rsi', 'bb_bbm']\n",
      "First few rows:\n",
      "         Date     close        volume      sma_20         macd        rsi  \\\n",
      "0  2021-05-10  55870.01  4.067497e+09  55031.2695  -401.466265  46.705675   \n",
      "1  2021-05-11  56747.52  2.395231e+09  55178.4830  -366.525278  49.016361   \n",
      "2  2021-05-12  49504.08  4.035173e+09  55067.8065  -912.797208  35.380073   \n",
      "3  2021-05-13  49700.60  5.919942e+09  54993.9350 -1314.708980  35.901091   \n",
      "4  2021-05-14  49887.96  2.156016e+09  54982.5335 -1599.668585  36.427363   \n",
      "\n",
      "       bb_bbm  \n",
      "0  55031.2695  \n",
      "1  55178.4830  \n",
      "2  55067.8065  \n",
      "3  54993.9350  \n",
      "4  54982.5335  \n",
      "Rearranged columns to place 'close' as the last column for prediction\n",
      "Training data size: 1148\n",
      "Testing data size: 288\n",
      "Training the LSTM model...\n",
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1475\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0291\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0132\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0038\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0028\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0022\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0048\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0035\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0027\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0051\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0032\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0019\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0014\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0012\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0019\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0040\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0064\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0051\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0029\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0028\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015\n",
      "Making predictions...\n",
      "\u001b[1m9/9\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
      "Mean Squared Error: 10291666.8610\n",
      "Root Mean Squared Error: 3208.0628\n",
      "Mean Absolute Error: 2473.2929\n",
      "Mean Absolute Percentage Error: 3.0134%\n",
      "Results preview:\n",
      "        Date    Actual     Predicted        Error\n",
      "0 2024-07-01  62841.27  61353.230469  1488.039531\n",
      "1 2024-07-02  62044.48  60709.621094  1334.858906\n",
      "2 2024-07-03  60157.20  59393.273438   763.926562\n",
      "3 2024-07-04  57041.11  57601.824219  -560.714219\n",
      "4 2024-07-05  56646.24  56769.964844  -123.724844\n",
      "Results saved to outputs/2025-04-23/lstm_14-16-31/lstm_prediction_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Load configuration for a specific model\n",
    "model_type = 'gru'  # Change this to 'lstm', 'arima', etc. as needed\n",
    "cfg = load_config(model_type)\n",
    "print(yaml.dump(cfg))\n",
    "\n",
    "# Convert config to Args object\n",
    "args = Args(cfg)\n",
    "# Print model parameters\n",
    "print(\"Model parameters:\")\n",
    "for key, value in vars(args).items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Get parameters from config\n",
    "model_name = cfg['model']['type']\n",
    "data_path = cfg['data']['path']\n",
    "test_size = cfg['data']['test_size']\n",
    "\n",
    "# Load and preprocess data\n",
    "data = load_and_preprocess_data(data_path)\n",
    "\n",
    "# Split data\n",
    "train_size = int(len(data) * (1 - test_size))\n",
    "train_data = data.iloc[:train_size]\n",
    "test_data = data.iloc[train_size:]\n",
    "print(f\"Training data size: {len(train_data)}\")\n",
    "print(f\"Testing data size: {len(test_data)}\")\n",
    "\n",
    "# Train model and make predictions\n",
    "predictions, model = train_and_predict(model_name, args, train_data, test_data)\n",
    "\n",
    "# Evaluate and save results\n",
    "metrics = evaluate_and_save_results(test_data, predictions, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 10291666.860962225, 'rmse': 3208.062789435741, 'mae': 2473.2928618706596, 'mape': 3.0134118506250656, 'results':           Date    Actual     Predicted        Error\n",
      "0   2024-07-01  62841.27  61353.230469  1488.039531\n",
      "1   2024-07-02  62044.48  60709.621094  1334.858906\n",
      "2   2024-07-03  60157.20  59393.273438   763.926562\n",
      "3   2024-07-04  57041.11  57601.824219  -560.714219\n",
      "4   2024-07-05  56646.24  56769.964844  -123.724844\n",
      "..         ...       ...           ...          ...\n",
      "283 2025-04-10  79554.96  78896.898438   658.061563\n",
      "284 2025-04-11  83386.00  80300.671875  3085.328125\n",
      "285 2025-04-12  85272.12  81221.421875  4050.698125\n",
      "286 2025-04-13  83730.92  80647.664062  3083.255937\n",
      "287 2025-04-14  84443.43  80986.750000  3456.680000\n",
      "\n",
      "[288 rows x 4 columns]}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /home/dung/Code/Project/intro-ds-project/venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from stock_data.csv\n",
      "Data shape: (1436, 7)\n",
      "Data columns: ['Date', 'close', 'volume', 'sma_20', 'macd', 'rsi', 'bb_bbm']\n",
      "First few rows:\n",
      "         Date     close        volume      sma_20         macd        rsi  \\\n",
      "0  2021-05-10  55870.01  4.067497e+09  55031.2695  -401.466265  46.705675   \n",
      "1  2021-05-11  56747.52  2.395231e+09  55178.4830  -366.525278  49.016361   \n",
      "2  2021-05-12  49504.08  4.035173e+09  55067.8065  -912.797208  35.380073   \n",
      "3  2021-05-13  49700.60  5.919942e+09  54993.9350 -1314.708980  35.901091   \n",
      "4  2021-05-14  49887.96  2.156016e+09  54982.5335 -1599.668585  36.427363   \n",
      "\n",
      "       bb_bbm  \n",
      "0  55031.2695  \n",
      "1  55178.4830  \n",
      "2  55067.8065  \n",
      "3  54993.9350  \n",
      "4  54982.5335  \n",
      "Rearranged columns to place 'close' as the last column for prediction\n",
      "âœ… Data loaded once:\n",
      "  Train size: 1148, Test size: 288\n",
      "\n",
      "ðŸš€ Running model: random_forest\n",
      "\n",
      "ðŸš€ Running model: sarimax\n",
      "\n",
      "ðŸš€ Running model: orbit\n",
      "\n",
      "ðŸš€ Running model: lstm\n",
      "\n",
      "ðŸš€ Running model: gru\n",
      "Training the LSTM model...\n",
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1457\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0282\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0126\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0039\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0034\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0030\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0023\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0019\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0016\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0016\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0018\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0033\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0046\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0055\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0049\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0033\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0015\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0015\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0016\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0021\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0029\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0057\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0061\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0047\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0027\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0014\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0017\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0029\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0040\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0053\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0055\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0043\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0012\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0017\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0026\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0031\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0022\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0016\n",
      "Making predictions...\n",
      "\u001b[1m9/9\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  \n",
      "Mean Squared Error: 9830412.2171\n",
      "Root Mean Squared Error: 3135.3488\n",
      "Mean Absolute Error: 2407.2968\n",
      "Mean Absolute Percentage Error: 2.9402%\n",
      "Results preview:\n",
      "        Date    Actual     Predicted        Error\n",
      "0 2024-07-01  62841.27  61437.296875  1403.973125\n",
      "1 2024-07-02  62044.48  60780.683594  1263.796406\n",
      "2 2024-07-03  60157.20  59462.519531   694.680469\n",
      "3 2024-07-04  57041.11  57677.015625  -635.905625\n",
      "4 2024-07-05  56646.24  56865.468750  -219.228750\n",
      "Results saved to outputs/2025-04-23/lstm_16-01-02/lstm_prediction_results.csv\n",
      "\n",
      "ðŸš€ Running model: arima\n",
      "\n",
      "ðŸš€ Running model: prophet\n",
      "\n",
      "ðŸš€ Running model: xgboost\n",
      "\n",
      "ðŸš€ Running model: neural_prophet\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data once\n",
    "model_type_example = 'gru'  # Just to get a sample config\n",
    "cfg = load_config(model_type_example)\n",
    "data_path = cfg['data']['path']\n",
    "test_size = cfg['data']['test_size']\n",
    "\n",
    "data = load_and_preprocess_data(data_path)\n",
    "train_size = int(len(data) * (1 - test_size))\n",
    "train_data = data.iloc[:train_size]\n",
    "test_data = data.iloc[train_size:]\n",
    "\n",
    "print(f\"âœ… Data loaded once:\")\n",
    "print(f\"  Train size: {len(train_data)}, Test size: {len(test_data)}\")\n",
    "\n",
    "# Store all metrics\n",
    "all_metrics = {}\n",
    "\n",
    "# Loop through each model type\n",
    "for model_type in MODELS.keys():\n",
    "    print(f\"\\nðŸš€ Running model: {model_type}\")\n",
    "    if model_type != 'gru':\n",
    "        continue\n",
    "    \n",
    "    cfg = load_config(model_type)\n",
    "    args = Args(cfg)\n",
    "    model_name = cfg['model']['type']\n",
    "\n",
    "    # Train and predict\n",
    "    predictions, model = train_and_predict(model_name, args, train_data, test_data)\n",
    "\n",
    "    # Evaluate\n",
    "    metrics = evaluate_and_save_results(test_data, predictions, model_name)\n",
    "    all_metrics[model_type] = metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'random_forest'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metric_names:\n\u001b[32m      5\u001b[39m     plt.figure()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     values = \u001b[43m[\u001b[49m\u001b[43mall_metrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mMODELS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      7\u001b[39m     plt.bar(MODELS.keys(), values)\n\u001b[32m      8\u001b[39m     plt.ylabel(metric.upper())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metric_names:\n\u001b[32m      5\u001b[39m     plt.figure()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     values = [\u001b[43mall_metrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m[metric] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MODELS.keys()]\n\u001b[32m      7\u001b[39m     plt.bar(MODELS.keys(), values)\n\u001b[32m      8\u001b[39m     plt.ylabel(metric.upper())\n",
      "\u001b[31mKeyError\u001b[39m: 'random_forest'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot selected metrics\n",
    "metric_names = ['mse', 'rmse', 'mae', 'mape']\n",
    "\n",
    "for metric in metric_names:\n",
    "    plt.figure()\n",
    "    values = [all_metrics[m][metric] for m in MODELS.keys()]\n",
    "    plt.bar(MODELS.keys(), values)\n",
    "    plt.ylabel(metric.upper())\n",
    "    plt.title(f\"{metric.upper()} Comparison Across Models\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
